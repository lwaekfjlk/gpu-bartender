<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>GPU Usage Calculator</title>
    <link href="styles.css" rel="stylesheet" />
    <script src="bundle.js" defer></script>
  </head>
  <body>
    <div class="container">
      <h1>GPU Usage Calculator for AI Model Training</h1>
      <img
        src="https://images.pexels.com/photos/17483874/pexels-photo-17483874.png?auto=compress&cs=tinysrgb&h=350"
        alt="AI Neural Network"
        class="hero-image"
      />

      <div class="calculator">
        <div class="input-section">
          <h2>
            <img
              src="https://images.pexels.com/photos/4937226/pexels-photo-4937226.jpeg?auto=compress&cs=tinysrgb&h=350"
              alt="AI Model Architecture"
            />
            Model Parameters
          </h2>
          <div class="form-group">
            <label>Precision:</label>
            <div class="toggle-buttons">
              <button class="toggle-btn active" id="mixedPrecision">mixed</button>
              <button class="toggle-btn" id="fullPrecision">full (fp32)</button>
            </div>
            <button class="info-btn" id="precisionInfo">?</button>
          </div>
          <div class="form-group">
            <label>Optimizer:</label>
            <div class="toggle-buttons">
              <button class="toggle-btn active" id="adamOptimizer">Adam</button>
              <button class="toggle-btn" id="sgdOptimizer">SGD</button>
            </div>
          <label class="checkbox-label">
            <input type="checkbox" id="momentum" checked> momentum
          </label>
          <div class="form-group">
            <label for="modelSize"
              >Model size (in millions of parameters):</label
            >
            <input type="number" id="modelSize" min="1" required />
          </div>
          <div class="form-group">
            <label for="batchSize">Batch size:</label>
            <input type="number" id="batchSize" min="1" required />
          </div>
          <div class="form-group">
            <label for="numGPUs">Number of GPUs:</label>
            <input type="number" id="numGPUs" value="1" />
          </div>

          <h2>
            <img
              src="https://images.pexels.com/photos/3993917/pexels-photo-3993917.jpeg?auto=compress&cs=tinysrgb&h=350"
              alt="GPU Chip"
            />
            GPU Selection
          </h2>
          <div class="form-group">
            <label for="gpuModel">Select GPU model:</label>
            <select id="gpuModel" required>
              <option value="">Choose a GPU</option>
              <option value="rtx3090">NVIDIA RTX 3090</option>
              <option value="rtx3080">NVIDIA RTX 3080</option>
              <option value="v100">NVIDIA Tesla V100</option>
              <option value="a100">NVIDIA A100</option>
            </select>
          </div>

          <h2>
            <img
              src="https://images.pexels.com/photos/8520081/pexels-photo-8520081.jpeg?auto=compress&cs=tinysrgb&h=350"
              alt="Training Progress"
            />
            Training Details
          </h2>
          <h2>Model Parameters</h2>
          <p>Model Parameters could be taken from config.json on HuggingFace or directly from model via model.config</p>
          <div class="form-group">
            <label for="parametersPreset">Parameters Preset:</label>
            <select id="parametersPreset">
              <option value="microsoft/phi-1_5">microsoft/phi-1_5</option>
            </select>
          </div>
          <div class="form-group">
            <label for="numParameters">Number of Parameters (billions):</label>
            <input type="number" id="numParameters" value="1.418" step="0.001" />
          </div>
          <div class="form-group">
            <label for="numLayers">Number of Layers:</label>
            <input type="number" id="numLayers" value="24" />
          </div>
          <div class="form-group">
            <label for="vocabSize">Vocab Size:</label>
            <input type="number" id="vocabSize" value="51200" />
          </div>
          <div class="form-group">
            <label for="hiddenSize">Hidden Size:</label>
            <input type="number" id="hiddenSize" value="2048" />
          </div>
          <div class="form-group">
            <label for="numAttentionHeads">Number of Attention Heads:</label>
            <input type="number" id="numAttentionHeads" value="32" />
          </div>
          <div class="form-group">
            <label for="intermediateSize">Intermediate Size:</label>
            <input type="number" id="intermediateSize" value="8192" />
          </div>
          <div class="form-group">
            <label for="numKeyValueHeads">Number of Key Value Heads:</label>
            <input type="number" id="numKeyValueHeads" value="32" />
          </div>
          <div class="form-group">
            <label>Expanding dimensionality within MLP block. Usually it is 4 x hidden size.</label>
          </div>
          <div class="form-group">
            <label>Might be different from number of attention heads when using Grouped Query Attention</label>
          </div>
        </div>

          <button id="calculateBtn">Calculate GPU Usage</button>
        </div>

        <div class="results-section">
          <h2>Estimation Result</h2>
          <div class="toggle-buttons">
            <button class="toggle-btn active" id="mibBtn">MiB</button>
            <button class="toggle-btn" id="gibBtn">GiB</button>
          </div>
          <div id="vramChart">
            <canvas id="vramChartCanvas"></canvas>
          </div>
          <p id="totalVRAM">Total VRAM usage is 27836 MiB</p>
          <div class="vram-details">
            <p><strong>CUDA Kernels</strong> use 1000 MiB of VRAM</p>
            <p>When PyTorch uses CUDA for the first time, it allocates between 300 MiB and 2 GiB of VRAM</p>
            <p><strong>Parameters</strong> use 8114 MiB of VRAM</p>
            <p>Number of Parameters (1.418 billion) × number of bytes per parameter (6; parameters are stored in both full precision and half precision)</p>
            <p><strong>Activations</strong> use 7104 MiB of VRAM</p>
            <p>Sum of sizes of all intermediate tensors during forward pass across all 24 layers. Activations size have quadratic dependence on Sequence Length.</p>
            <p><strong>Gradients</strong> use 5409 MiB of VRAM</p>
            <p>Gradient is stored for each parameter in full precision, so it is Number of Parameters (1.418 billion) × number of bytes per parameter (4)</p>
            <p><strong>First Moments</strong> use 5409 MiB of VRAM</p>
            <p>Optimizer stores moving average of gradients for each parameter in full precision, so it is Number of Parameters (1.418 billion) × number of bytes per parameter (4)</p>
            <p><strong>Output tensor</strong> uses 800 MiB of VRAM</p>
            <p>Batch Size (4) × Sequence Length (512) × Vocabulary Size (51200) × number of bytes per parameter (4) × 2 (storing probabilities after softmax output which are the same size as output)</p>
          </div>
        </div>
      </div>
    </div>

    <footer>
      <div class="social-icons">
        <a href="#"
          ><img
            src="https://images.pexels.com/photos/267350/pexels-photo-267350.jpeg?auto=compress&cs=tinysrgb&h=350"
            alt="Social Media"
        /></a>
        <a href="#"
          ><img
            src="https://images.pexels.com/photos/267350/pexels-photo-267350.jpeg?auto=compress&cs=tinysrgb&h=350"
            alt="Social Media"
        /></a>
        <a href="#"
          ><img
            src="https://images.pexels.com/photos/267350/pexels-photo-267350.jpeg?auto=compress&cs=tinysrgb&h=350"
            alt="Social Media"
        /></a>
      </div>
      <p>&copy; 2023 GPU Usage Calculator. All rights reserved.</p>
    </footer>
  </body>
</html>
